# RDD2020 â†’ YOLOv8 (PyTorch â†’ TFLite)

Yol Ã§atlak/hasar tespiti iÃ§in **Road Damage Dataset 2020 (RDD2020)** ile YOLOv8 modeli eÄŸitme, doÄŸrulama, Streamlit ile etkileÅŸimli arayÃ¼z ve **TFLite (FP16 + NMS)** dÄ±ÅŸa aktarma rehberi.

---

## ğŸŒŸ Ã–zellikler

* VOC **XML â†’ YOLO** etikete otomatik dÃ¶nÃ¼ÅŸÃ¼m
* **Train/Val** ayrÄ±mÄ± ve **data.yaml** Ã¼retimi
* **YOLOv8** eÄŸitim, doÄŸrulama ve metrikler (mAP\@0.50, mAP\@0.50:0.95)
* **Streamlit Web UI**: tek/Ã§oklu resim yÃ¼kleme, eÅŸik ayarlarÄ± (conf/IoU/imgsz), Ã§Ä±ktÄ± indirme
* **TFLite (FP16)** export (grafikte **NMS** dahil)

image.png
indir.png

---

## 1) Proje Ã–zeti

* **Veri kÃ¼mesi**: RDD2020 (*Czech*, *Japan*, *India* alt klasÃ¶rleri)
* **AmaÃ§**: VOC kutularÄ±nÄ± YOLO formatÄ±na Ã§evirip YOLOv8 ile eÄŸitmek
* **Ã‡Ä±ktÄ±lar**:

  * Dataset: `/working/rdd2020_subset_yolo/` â†’ `images/{train,val}`, `labels/{train,val}`, `data.yaml`
  * EÄŸitim: `runs/detect/train/weights/{best.pt,last.pt}`
  * DaÄŸÄ±tÄ±m: `best_float16.tflite`

---

## 2) Dizin YapÄ±sÄ± (Beklenen)

```bash
archive/
â””â”€ train/
   â”œâ”€ Czech/
   â”‚  â”œâ”€ images/*.jpg
   â”‚  â””â”€ annotations/xmls/*.xml
   â”œâ”€ India/
   â”‚  â”œâ”€ images/*.jpg
   â”‚  â””â”€ annotations/xmls/*.xml
   â””â”€ Japan/
      â”œâ”€ images/*.jpg
      â””â”€ annotations/xmls/*.xml

/working/rdd2020_subset_yolo/
â”œâ”€ images/{train,val}/*.jpg
â”œâ”€ labels/{train,val}/*.txt
â””â”€ data.yaml
```

---

## 3) Kurulum

```bash
# YOLOv8 + yardÄ±mcÄ± kÃ¼tÃ¼phaneler
pip install ultralytics==8.* tqdm pyyaml pillow numpy pandas
# (GPU kullanacaksan) uygun Torch + CUDA sÃ¼rÃ¼mÃ¼nÃ¼ ayrÄ±ca kur
```

> **Windows ipucu**: Yol ayracÄ± (`\`) ve TÃ¼rkÃ§e/boÅŸluk iÃ§eren klasÃ¶r adlarÄ± sorun Ã§Ä±karabilir; mÃ¼mkÃ¼nse ASCII klasÃ¶r adlarÄ± kullanÄ±n.

---

## 4) Veri HazÄ±rlama (VOC XML â†’ YOLO)

Kodun yaptÄ±ÄŸÄ± adÄ±mlar:

1. Ãœlkeleri gezer (`Czech, Japan, India`)
2. XMLâ€™leri toplar ve `subset_ratio` ile altkÃ¼me seÃ§er
3. `split_ratio` ile **train/val** bÃ¶ler
4. VOC kutularÄ±nÄ± YOLO formatÄ±na (class x\_center y\_center w h, normalize) Ã§evirir
5. `data.yaml` dosyasÄ±nÄ± Ã¼retir

### Ã–rnek Ã‡alÄ±ÅŸtÄ±rma (script)

```bash
python prepare_rdd2020_yolo.py \
  --base_path archive/train \
  --out /working/rdd2020_subset_yolo \
  --countries Czech Japan India \
  --subset_ratio 1.0 \
  --split_ratio 0.8
```

**data.yaml** (otomatik):

```yaml
train: /working/rdd2020_subset_yolo/images/train
val:   /working/rdd2020_subset_yolo/images/val
nc: <sÄ±nÄ±f_sayÄ±sÄ±>
names: [<sÄ±nÄ±f_0>, <sÄ±nÄ±f_1>, ...]
```

> **Not**: SÄ±nÄ±f kimlikleri veri hazÄ±rlama sÄ±rasÄ±nda ilk karÅŸÄ±laÅŸÄ±lan sÄ±raya gÃ¶re oluÅŸturulur. Tekrar Ã¼retilebilirlik iÃ§in sabit bir sÄ±nÄ±f listesi tutmanÄ±z Ã¶nerilir.

---

## 5) YOLOv8 EÄŸitimi & DoÄŸrulama

```python
from ultralytics import YOLO
import os
os.environ['WANDB_MODE'] = 'disabled'

model = YOLO('yolov8s.pt')
model.train(
    data='/working/rdd2020_subset_yolo/data.yaml',
    epochs=20,
    imgsz=640,
    device=0  # CUDA:0, CPU iÃ§in -1
)

metrics = model.val()
print(f"mAP50: {metrics.box.map50:.4f}")
print(f"mAP50-95: {metrics.box.map:.4f}")
```

**Ã‡Ä±ktÄ±lar**: `runs/detect/train/weights/best.pt`, `results.png`, `confusion_matrix.png` vb.

---

## 6) Modeli Kaydetme

Ultralytics eÄŸitim sonunda `best.pt` Ã¼retir. Ä°stersen ayrÄ±ca:

```python
model.save('best_model.pt')
```

---

## 7) TFLiteâ€™a DÄ±ÅŸa Aktarma (FP16 + NMS)

```python
from ultralytics import YOLO
m = YOLO('runs/detect/train/weights/best.pt')  # veya 'best_model.pt'
m.export(
    format='tflite',
    imgsz=640,
    half=True,  # FP16
    nms=True    # grafiÄŸe NMS ekler
)
# => best_float16.tflite
```

> `imgsz` eÄŸitimdeki ile aynÄ± olmalÄ±. BazÄ± ortamlarda TensorFlow/FlatBuffers gerekebilir.

---

## 8) HÄ±zlÄ± Ã‡Ä±karÄ±m (Inference)

```python
from ultralytics import YOLO
model = YOLO('runs/detect/train/weights/best.pt')
results = model('sample.jpg')
results[0].save('out/')
```

---

## 9) Streamlit Web UI

`streamlit_app.py` dosyasÄ± ile interaktif arayÃ¼z:

**Kurulum**

```bash
pip install streamlit ultralytics pillow pandas numpy
```

**Ã‡alÄ±ÅŸtÄ±rma**

```bash
streamlit run streamlit_app.py
```

**KullanÄ±m**

* Sidebar â†’ **Model aÄŸÄ±rlÄ±ÄŸÄ± (.pt)**: `runs/detect/train/weights/best.pt`
* **Image size / Conf / IoU / Max detections** ayarlarÄ±nÄ± yap
* Tek/Ã§oklu resim yÃ¼kle, **Ã§Ä±ktÄ±yÄ± indir (PNG)**
* (Opsiyonel) `data.yaml` gir â†’ **Validation Ã§alÄ±ÅŸtÄ±r**

**Notlar**

* `@st.cache_resource` ile model tek sefer yÃ¼klenir
* YÃ¼kleme boyutu sÄ±nÄ±rÄ± iÃ§in `~/.streamlit/config.toml`:

  ```toml
  [server]
  maxUploadSize = 512
  ```
* Ã‡oklu sekmesinde CSV/PNG indirme butonlarÄ± eklenebilir (Ã¶rnek kodda hazÄ±r ÅŸablonlar var)

---

## 10) KarÅŸÄ±laÅŸÄ±labilecek Hatalar & Ã‡Ã¶zÃ¼mler

* **`Image file ... does not exist. Skipping.`** â†’ XML `filename` ile gerÃ§ek dosya adÄ± uyuÅŸmuyor olabilir. UzantÄ± farklarÄ±nÄ± (jpg/JPG/png) normalize edin.
* **`Size missing in annotation ...`** â†’ `<size>` yoksa Ã¶rnek atlanÄ±r; hatalÄ± XMLâ€™i dÃ¼zeltin.
* **`ET.ParseError`** â†’ Bozuk XML; problemli dosyalarÄ± loglayÄ±p temizleyin.
* **CUDA gÃ¶rÃ¼nmÃ¼yor** â†’ `device=-1` ile CPUâ€™da deneyin; PyTorchâ€“CUDA sÃ¼rÃ¼m eÅŸleÅŸmesini kontrol edin.
* **SÄ±nÄ±f sÄ±rasÄ± deÄŸiÅŸken** â†’ SÄ±nÄ±fâ€“ID haritasÄ±nÄ± sabitleyin.

---

## 11) Ä°yileÅŸtirme Ä°puÃ§larÄ±

* **Model boyutu**: `yolov8n/s/m/l` karÅŸÄ±laÅŸtÄ±rÄ±n (hÄ±z/doÄŸruluk)
* **Epoch/Batch/LR**: 20 yerine 50â€“100 denenebilir; erken durdurma (patience)
* **imgsz**: 640 â†’ 768/960 doÄŸruluÄŸu artÄ±rabilir (maliyet artar)
* **Augmentasyon**: mosaic, mixup, hsv, degrees vb.
* **Dengesiz sÄ±nÄ±flar**: oversampling/weighted loss stratejileri

---

## 12) HÄ±zlÄ± Komut Ã–zeti

```bash
  data=/working/rdd2020_subset_yolo/data.yaml imgsz=640 device=0

#  Export (TFLite FP16)
yolo export model=runs/detect/train/weights/best.pt format=tflite imgsz=640 half=True nms=True
```

---

## 13) Lisans & AtÄ±f

* RDD2020 veri kÃ¼mesi (https://www.kaggle.com/datasets/ziedkelboussi/rdd2020-dataset/data)
* Ultralytics YOLOv8 kullanÄ±m https://github.com/ultralytics/ultralytics
https://github.com/sekilab/RoadDamageDetector

---

## Ek â€” Argparseâ€™lÄ± Veri HazÄ±rlama Ä°skeleti

*(Ä°sterseniz script olarak kullanÄ±n.)*

```python
# prepare_rdd2020_yolo.py (iskelet)
import os, random, shutil, yaml
import xml.etree.ElementTree as ET
from tqdm import tqdm
import argparse

parser = argparse.ArgumentParser()
parser.add_argument('--base_path', type=str, required=True)
parser.add_argument('--out', type=str, required=True)
parser.add_argument('--countries', nargs='+', default=['Czech','Japan','India'])
parser.add_argument('--subset_ratio', type=float, default=1.0)
parser.add_argument('--split_ratio', type=float, default=0.8)
args = parser.parse_args()

base_path = args.base_path
output_base_path = args.out
countries = args.countries
subset_ratio = args.subset_ratio
split_ratio = args.split_ratio

for split in ['train','val']:
    os.makedirs(os.path.join(output_base_path, 'images', split), exist_ok=True)
    os.makedirs(os.path.join(output_base_path, 'labels', split), exist_ok=True)

class_name_to_id = {}

for country in countries:
    annotations_xmls_path = os.path.join(base_path, country, 'annotations', 'xmls')
    images_path = os.path.join(base_path, country, 'images')

    xml_files = [f for f in os.listdir(annotations_xmls_path) if f.lower().endswith('.xml')]
    num_subset_files = max(1, int(len(xml_files) * subset_ratio))
    subset_xml_files = random.sample(xml_files, num_subset_files)

    annotated_images = []
    for xml_file in subset_xml_files:
        ann_path = os.path.join(annotations_xmls_path, xml_file)
        try:
            tree = ET.parse(ann_path)
            root = tree.getroot()
            filename = root.findtext('filename')
            if not filename:
                filename = os.path.splitext(xml_file)[0] + '.jpg'
            annotated_images.append((filename, xml_file))
        except ET.ParseError as e:
            print(f"Error parsing {ann_path}: {e}")
            continue

    random.shuffle(annotated_images)
    split_index = int(len(annotated_images) * split_ratio)
    train_images = annotated_images[:split_index]
    val_images = annotated_images[split_index:]

    for split, image_list in zip(['train', 'val'], [train_images, val_images]):
        for image_file, xml_file in tqdm(image_list, desc=f"Processing {country} {split} set"):
            image_src_path = os.path.join(images_path, image_file)
            image_dst_path = os.path.join(output_base_path, 'images', split, image_file)
            label_dst_path = os.path.join(output_base_path, 'labels', split, f"{os.path.splitext(image_file)[0]}.txt")
            ann_path = os.path.join(annotations_xmls_path, xml_file)

            if not os.path.exists(image_src_path):
                print(f"Missing: {image_src_path}")
                continue

            shutil.copy(image_src_path, image_dst_path)

            try:
                tree = ET.parse(ann_path)
                root = tree.getroot()
            except ET.ParseError as e:
                print(f"Error parsing {ann_path}: {e}")
                continue

            size = root.find('size')
            if size is None:
                print(f"Size missing in {ann_path}")
                continue
            width = int(size.findtext('width'))
            height = int(size.findtext('height'))

            with open(label_dst_path, 'w') as label_file:
                for obj in root.findall('object'):
                    class_name = obj.findtext('name')
                    if not class_name:
                        continue
                    if class_name not in class_name_to_id:
                        class_name_to_id[class_name] = len(class_name_to_id)
                    class_id = class_name_to_id[class_name]

                    b = obj.find('bndbox')
                    if b is None:
                        continue
                    xmin = float(b.findtext('xmin'))
                    ymin = float(b.findtext('ymin'))
                    xmax = float(b.findtext('xmax'))
                    ymax = float(b.findtext('ymax'))

                    x_center = ((xmin + xmax) / 2) / width
                    y_center = ((ymin + ymax) / 2) / height
                    bw = (xmax - xmin) / width
                    bh = (ymax - ymin) / height

                    label_file.write(f"{class_id} {x_center} {y_center} {bw} {bh}
")

# data.yaml
data = {
    'train': os.path.join(output_base_path, 'images', 'train'),
    'val': os.path.join(output_base_path, 'images', 'val'),
    'nc': len(class_name_to_id),
    'names': list(class_name_to_id.keys()),
}
with open(os.path.join(output_base_path, 'data.yaml'), 'w') as f:
    yaml.dump(data, f, default_flow_style=False)

print('Done. Classes:')
for k, v in class_name_to_id.items():
    print(v, k)
```
